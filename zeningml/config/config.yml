active_stack: production_stack

stacks:
  production_stack:
    orchestrator: airflow
    artifact_store: s3
    metadata_store: mlflow
    experiment_tracker: mlflow

# config/config.yml
artifact_store:
  type: s3
  bucket_name: my-ml-bucket

orchestration:
  type: prefect

aws:
  access_key: YOUR_ACCESS_KEY
  secret_key: YOUR_SECRET_KEY


mlflow:
  tracking_uri: "http://mlflow-server:5000"
  experiment_name: "production-runs"

metadata_store:
  type: "mlflow"

versioning:
  enabled: true
  git_integration: true

aws:
  bucket_name: "ml-artifacts-bucket"
  access_key: "AKIA..."
  secret_key: "secret"

folder_path:
  artifacts: "s3://ml-artifacts-bucket/pipelines"

feature_store:
  path: "./feature_repo"
  entities:
    - name: "customer"
      description: "Customer features"
  online_store:
    type: "redis"
    host: "redis.prod.svc.cluster.local"

monitoring:
  port: 8000
  drift_threshold: 0.05
  accuracy_threshold: 0.75

cicd:
  github_token: ${GITHUB_TOKEN}
  k8s_endpoint: "https://k8s-cluster/api"
  image_name: "ml-model"
  version: "v1.2.0"

validation:
  expectation_suite: "taxi_suite.json"

explainability:
  methods: ["shap", "lime"]
  sample_size: 100

tuning:
  backend: "optuna"
  n_trials: 100
  metric: "accuracy"
  direction: "maximize"

deployment:
  strategy: "bandit"
  initial_split: [0.7, 0.3]
  metrics_window: 24h

alerting:
  slack:
    token: ${SLACK_TOKEN}
    channel: "#ml-alerts"
  pagerduty:
    integration_key: ${PD_KEY}

feature_store:
  backend: "tecton"
  tecton:
    workspace: "prod"
    feature_service: "fraud_detection_features"

model_registry:
  backend: "mlflow"
  stages: ["Staging", "Production"]
  approval_threshold: 0.95

rollback:
  performance_threshold: 0.15
  max_history_size: 10

data_quality:
  batch_size: 1000
  expectations_path: "validation/expectations/"
  feature_expectations: "feature_suite.json"

cloud_monitoring:
  cloudwatch:
    namespace: "ML/Metrics"
  datadog:
    api_key: ${DATADOG_API_KEY}
    app_key: ${DATADOG_APP_KEY}

feature_store:
  validation_window: 7d
  backfill_schedule: "@daily"


ab_testing:
  active_experiments:
    - name: "fraud_model_v2"
      variants: ["v1", "v2"]
      traffic_split: [0.5, 0.5]
      metrics: ["accuracy", "recall"]

cost_monitoring:
  cloud: "aws"
  budget_alert: 1000  # USD
  resource_tags:
    - "ml-pipeline"

security:
  encryption_key: ${ENCRYPTION_KEY}
  compliance_checks:
    - "pii"
    - "fairness"
    - "gdpr"

serving:
  server_type: "tensorflow"
  scaling:
    min_replicas: 2
    max_replicas: 10

cloud:
  primary: "aws"
  fallback: "gcp"
  resource_mapping:
    aws:
      storage: "s3://ml-artifacts"
    gcp:
      storage: "gs://ml-artifacts"


distillation:
  enabled: true
  temperature: 2
  target_size: 50MB
  
gpu_monitoring:
  utilization_threshold: 85%
  temperature_threshold: 85C

siem:
  endpoint: "https://splunk.prod:8088"
  format: "CEF"
  integrations:
    - "splunk"
    - "qradar"

watermark:
  secret_key: ${WATERMARK_SECRET}
  strength: 0.01

federated:
  strategy: "fedavg"
  rounds: 20
  ssl:
    cert_path: "/ssl/cert.pem"
  clients:
    min_online: 5
    max_per_round: 10